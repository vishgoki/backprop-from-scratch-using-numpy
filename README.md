# backprop-from-scratch-using-numpy
Implemented back-propagation from scratch in Python, focusing on basic operations (addition, multiplication, power, ReLU) and manual gradient computation for the MNIST dataset. This project, utilizing only math and numpy, aimed to deepen my understanding of neural networks' core algorithms without relying on frameworks like PyTorch or TensorFlow.
